# -*- coding: utf-8 -*-
"""Ecommerce_Text_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oVoxd6q6NQfuOkJ_A0RzzvfTSQrwZZbE

# Performing Text Classification on dataset ecommerce.csv

**Importing necessary libraries**
"""

import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Embedding,LSTM,GRU,SimpleRNN,Bidirectional,Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing import sequence
from keras.utils import np_utils

from sklearn.metrics import classification_report
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""Reading the dataset and displaying first five rows"""

df=pd.read_csv('/ecommerce (2).csv')
df.head()

df.shape

"""Dropping unnecessary column"""

df.drop('Unnamed: 0',axis=1,inplace=True)

"""Checking null values"""

df.isnull().sum()

"""Checking number of categories with values in label column"""

df['label'].value_counts()

"""Checking duplicate rows"""

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.head(2)

"""Collecting all different categories data in 4 seperate variables to display using WordCloud"""

Books=" ".join(df[df['label']=='Books']['text'])
Household=" ".join(df[df['label']=='Household']['text'])
Clothing_Accessories=" ".join(df[df['label']=='Clothing & Accessories']['text'])
Electronics=" ".join(df[df['label']=='Electronics']['text'])

wc=WordCloud(width=800,height=800,background_color='black',min_font_size=10)
wc.generate(Books)

plt.figure(figsize=(7,5))
plt.imshow(wc)
plt.axis('off')
plt.show()

wc=WordCloud(width=800,height=800,background_color='white',min_font_size=10)
wc.generate(Household)

plt.figure(figsize=(7,5))
plt.imshow(wc)
plt.axis('off')
plt.show()

"""Seperating the two columns in X and Y"""

X=df['text']
Y=df['label']

"""Using LabelEncoder to convert characters into numerical data
i.e 1,2,3,4 since we have 4 categories
"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
Y=le.fit_transform(Y)

"""Using one hot encoding to again convert the numbers into 1 and 0"""

Y=np_utils.to_categorical(Y,num_classes=4)

print(Y)

""" Applying train test split"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)

"""Converting words into tokens using Tokenizer"""

tokenizer=Tokenizer()
tokenizer.fit_on_texts(X_train)

vocabulary=tokenizer.index_word
vocab_length=len(vocabulary)
print(vocabulary)
print(vocab_length)

"""Converting dictionary to a sequence of integers"""

train_sequence=tokenizer.texts_to_sequences(X_train)
print(train_sequence)

doc_length=[]
for doc in train_sequence:
  doc_length.append(len(doc))
print(doc_length)

max(doc_length)

"""Getting the value of maximum document length of 99% of the documents"""

print(np.quantile(doc_length,0.95))
print(np.quantile(doc_length,0.99))

max_length=53

"""Performing padding operation on all the documents to get equal length of all documents"""

train_matrix=sequence.pad_sequences(train_sequence,maxlen=max_length)
print(train_matrix)

"""Performing same operations on input testing data except for fitting"""

test_sequence=tokenizer.texts_to_sequences(X_test)
test_matrix=sequence.pad_sequences(test_sequence,maxlen=max_length)
print(test_matrix)

"""Creating RNN model and training the data
Generating Classification report
"""

model=Sequential()
model.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,
                mask_zero=True))
model.add(SimpleRNN(64))
model.add(Dense(units=32,activation='tanh'))
model.add(Dropout(0.2))
model.add(Dense(units=16,activation='tanh'))

model.add(Dense(units=4,activation='softmax'))
model.compile(optimizer='adam',loss='categorical_crossentropy')

model.fit(train_matrix,Y_train,epochs=10,batch_size=128)

Y_pred=model.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating Bidirectional RNN model and training the data
Generating Classification report
"""

model1=Sequential()
model1.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model1.add(Bidirectional(SimpleRNN(64)))

model1.add(Dense(units=32,activation='tanh'))
model1.add(Dropout(0.2))
model1.add(Dense(units=16,activation='tanh'))
model1.add(Dense(units=4,activation='softmax'))

model1.compile(optimizer='adam',loss='categorical_crossentropy')

model1.fit(train_matrix,Y_train,epochs=10,batch_size=64)

Y_pred=model1.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating Multilayer RNN model and training the data
Generating Classification report
"""

model2=Sequential()
model2.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model2.add(SimpleRNN(64,return_sequences=True))
model2.add(SimpleRNN(64,return_sequences=True))
model2.add(SimpleRNN(64))

model2.add(Dense(units=32,activation='tanh'))
model2.add(Dropout(0.2))
model2.add(Dense(units=16,activation='tanh'))
model2.add(Dense(units=4,activation='softmax'))

model2.compile(optimizer='adam',loss='categorical_crossentropy')

model2.fit(train_matrix,Y_train,epochs=10,batch_size=64)

Y_pred=model2.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating LSTM model and training the data
Generating Classification report
"""

model3=Sequential()
model3.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model3.add(LSTM(64))

model3.add(Dense(units=32,activation='tanh'))
model3.add(Dropout(0.2))
model3.add(Dense(units=16,activation='tanh'))
model3.add(Dense(units=4,activation='softmax'))

model3.compile(optimizer='adam',loss='categorical_crossentropy')

model3.fit(train_matrix,Y_train,epochs=10,batch_size=64)

Y_pred=model3.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating Bidirectional LSTM model and training the data
Generating Classification report
"""

model4=Sequential()
model4.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model4.add(Bidirectional(LSTM(64)))

model4.add(Dense(units=32,activation='tanh'))
model4.add(Dropout(0.2))
model4.add(Dense(units=16,activation='tanh'))
model4.add(Dense(units=4,activation='softmax'))
model4.compile(optimizer='adam',loss='categorical_crossentropy')

model4.fit(train_matrix,Y_train,epochs=10,batch_size=64)

Y_pred=model4.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating Multilayer LSTM model and training the data
Generating Classification report
"""

model5=Sequential()
model5.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model5.add(LSTM(64,return_sequences=True))
model5.add(LSTM(64,return_sequences=True))
model5.add(LSTM(64))
model5.add(Dense(units=32,activation='tanh'))
model5.add(Dropout(0.2))
model5.add(Dense(units=16,activation='tanh'))
model5.add(Dense(units=4,activation='softmax'))

model5.compile(optimizer='adam',loss='categorical_crossentropy')

model5.fit(train_matrix,Y_train,epochs=10,batch_size=128)

Y_pred=model5.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating GRU model and training the data
Generating Classification report
"""

model6=Sequential()
model6.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model6.add(GRU(64))

model6.add(Dense(units=32,activation='tanh'))
model6.add(Dropout(0.2))
model6.add(Dense(units=16,activation='tanh'))
model6.add(Dense(units=4,activation='softmax'))
model6.compile(optimizer='adam',loss='categorical_crossentropy')

model6.fit(train_matrix,Y_train,epochs=10,batch_size=64)

Y_pred=model6.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating Bidirectional GRU model and training the data
Generating Classification report
"""

model7=Sequential()
model7.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model7.add(Bidirectional(GRU(64)))

model7.add(Dense(units=32,activation='tanh'))
model7.add(Dropout(0.2))
model7.add(Dense(units=16,activation='tanh'))
model7.add(Dense(units=4,activation='softmax'))
model7.compile(optimizer='adam',loss='categorical_crossentropy')

model7.fit(train_matrix,Y_train,epochs=10,batch_size=64)

Y_pred=model7.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""Creating Multilayer GRU model and training the data
Generating Classification report
"""

model8=Sequential()
model8.add(Embedding(input_dim=vocab_length+1,output_dim=100,input_length=max_length,mask_zero=True))
model8.add(GRU(64,return_sequences=True))
model8.add(GRU(64,return_sequences=True))
model8.add(GRU(64))

model8.add(Dense(units=32,activation='tanh'))
model8.add(Dropout(0.2))
model8.add(Dense(units=16,activation='tanh'))
model8.add(Dense(units=4,activation='softmax'))
model8.compile(optimizer='adam',loss='categorical_crossentropy')

model8.fit(train_matrix,Y_train,epochs=10,batch_size=128)

Y_pred=model8.predict(test_matrix)
Y_pred=np.where(Y_pred>0.5,1,0)
print(classification_report(Y_test,Y_pred))

"""We got the best f1 score for this dataset by using a bidirectional GRU model i.e model7"""

df['label'].value_counts()

"""# 1st Label : Books
# 2nd Label : Clothing & Accessories
# 3rd Label : Electronics
# 4th Label : Household

Defining a function for predicting labels using model7: Bidirectional GRU
"""

def text_prediction(text):
  text_seq=tokenizer.texts_to_sequences(text)
  text_matrix=sequence.pad_sequences(text_seq,maxlen=max_length)
  pred=model7.predict(text_matrix)
  labels=['Books','Clothing & Accessories','Electronics','Household']
  print(pred,labels[np.argmax(pred)])

text1=['rts Dual USB Universal Travel Adapter, International All in One Worldwide Travel Adapter and Wall Charger with USB Ports with Multi Type Power Outlet USB 2.1A,100-250 Voltage Travel Charger (Black)']
text2=['Peterman Regular Fit Hosiery Cotton Full Sleeves Sweatshirt T-shirt & Jogger Pant']
text3=['Solimo Cygnus Engineered Wood 2 Door TV Cabinet / TV Entertainment Unit (Brown, Oak )']
text4=['Think and Grow Rich: THE 21st CENTURY EDITION']

text_prediction(text1)

text_prediction(text2)

text_prediction(text3)

text_prediction(text4)

"""All the preictions are accurate,hence
Bidirectional GRU is the best model for this dataset
"""





















"""# New Section"""